# Проект парсинга PEP асинхронным методом с помощью фреймворка Scrapy
Парсер номеров, названий и статусов с помощью Scrapy

## Описание
Этот парсер собирает данные с официального сайта [Python Enhancement Proposals / PEP](https://peps.python.org/)

- **scrapy crawl pep**: получить 2 файла в формате [csv](https://ru.wikipedia.org/wiki/CSV)
Первый предоставляет информацию по номеру, названию и актуальному статусу документа PEP.
Второй подсчитывает уникальные значения статусов, их количество и выводит тотальные значения.

## Стек технологий

Проект реализован на Python с использованием следующих библиотек:
- [logging](https://docs.python.org/3/library/logging.html) — встроенное логирование
- [Scrapy](https://scrapy.org/) - фреймворк с открытым исходным кодом, разработанный на языке программирования Python, предназначенный для эффективного извлечения, обработки и структурирования данных из веб-источников.

## Запуск парсера

Убедитесь, что у вас установлен Python 3.10+ и менеджер пакетов pip. Затем выполните следующие шаги:

1. Клонируйте репозиторий или скопируйте проект на другой компьютер.
2. Установите зависимости:
```
pip install -r requirements.txt
```
3. Запустите парсер
```
scrapy crawl pep  
```

## Автор

Разработано в рамках учебного проекта Yandex Практикум. Автор [Новожилов Антон Алексеевич](https://github.com/AntonNovozhilov)